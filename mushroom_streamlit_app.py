# mushroom_streamlit_app.py
import streamlit as st
from PIL import Image
import torch
import torchvision.models as models
import torch.nn as nn
from torchvision import transforms
import os
import urllib.request

# æ¨¡å‹æ–‡ä»¶ä¸‹è½½
MODEL_PATH = "mushroom_resnet50.pth"
MODEL_URL = "https://huggingface.co/LIUXINYI-huaizhi/mushroom-detector/resolve/main/mushroom_resnet50.pth"

def download_model():
    if not os.path.exists(MODEL_PATH):
        with st.spinner("æ­£åœ¨ä¸‹è½½æ¨¡å‹..."):
            urllib.request.urlretrieve(MODEL_URL, MODEL_PATH)

# æ¨¡å‹åŠ è½½
def load_model(model_path):
    checkpoint = torch.load(model_path, map_location='cpu')
    state_dict = {
        k.replace('model.', ''): v
        for k, v in checkpoint['model_state_dict'].items()
    }
    model = models.resnet50(weights=None)
    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_ftrs, 1024),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(1024, 1),
        nn.Sigmoid()
    )
    model.load_state_dict(state_dict)
    model.eval()
    transform = transforms.Compose([
        transforms.Resize((checkpoint['input_size'], checkpoint['input_size'])),
        transforms.ToTensor(),
        transforms.Normalize(mean=checkpoint['transform_mean'], std=checkpoint['transform_std'])
    ])
    return model, transform, checkpoint['class_names']

# æ¨ç†å‡½æ•°
def predict_image(image, model, transform):
    image = image.convert('RGB')
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(image)
        prob = output.item()
        pred = 1 if prob > 0.5 else 0
    return pred, prob

# æ–‡å­—æé†’å‡½æ•°
def get_interpretation(pred, prob):
    if pred == 1:
        if prob >= 0.9:
            msg = "â˜ ï¸ é«˜ç½®ä¿¡åº¦æ¯’è˜‘è‡ï¼Œä¸¥ç¦é£Ÿç”¨"
        elif prob >= 0.7:
            msg = "âš ï¸ æœ‰æ¯’å¯èƒ½æ€§é«˜ï¼Œè¯·å‹¿é£Ÿç”¨"
        else:
            msg = "â“ ç–‘ä¼¼æ¯’è˜‘è‡ï¼Œè¯·è°¨æ…å¤„ç†"
    else:
        if prob <= 0.3:
            msg = "âœ… å¯é£Ÿè˜‘è‡ï¼Œå¯ä¿¡åº¦é«˜"
        elif prob <= 0.45:
            msg = "âš ï¸ å¯é£Ÿè˜‘è‡ï¼Œä½†ç–‘ä¼¼æœ‰æ¯’ï¼Œè¯·è°¨æ…é£Ÿç”¨"
        else:
            msg = "â“ æ¨¡å‹ä¸ç¡®å®šï¼Œå»ºè®®é¿å…é£Ÿç”¨"
    return msg

# Streamlit é¡µé¢é…ç½®
st.set_page_config(page_title="è˜‘è‡æ¯’æ€§è¯†åˆ«ç³»ç»Ÿ", layout="centered")
st.markdown("""
<style>
body {
    background-color: #f5f5f5;
}
.stApp {
    max-width: 800px;
    margin: auto;
    font-family: 'Arial';
}
.title-box {
    background: linear-gradient(90deg, #ff416c, #ff4b2b);
    color: white;
    padding: 1em;
    border-radius: 12px;
    text-align: center;
}
.warning-box {
    background-color: #ffcccc;
    color: red;
    border: 2px solid red;
    border-radius: 10px;
    padding: 1em;
    text-align: center;
}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='title-box'><h2>ğŸ„ è˜‘è‡æ¯’æ€§è¯†åˆ«ç³»ç»Ÿ</h2></div>", unsafe_allow_html=True)
st.markdown("ä¸Šä¼ è˜‘è‡å›¾ç‰‡ï¼Œæˆ‘ä»¬å°†åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ¯’å“ç§ï¼")

# ç¤ºä¾‹å›¾ç‰‡
st.markdown("**ç¤ºä¾‹å›¾æµ‹è¯•ï¼š**")
col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸš« æœ‰æ¯’è˜‘è‡ç¤ºä¾‹"):
        image = Image.open("toxic_example.jpg")
        st.image(image, caption="ç¤ºä¾‹ï¼šæœ‰æ¯’è˜‘è‡", use_container_width=True)
        download_model()
        model, transform, class_names = load_model(MODEL_PATH)
        pred, prob = predict_image(image, model, transform)
        msg = get_interpretation(pred, prob)
        if pred == 1:
            st.markdown(f"<div class='warning-box'>{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰</div>", unsafe_allow_html=True)
        else:
            st.success(f"{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰")

with col2:
    if st.button("âœ… å¯é£Ÿè˜‘è‡ç¤ºä¾‹"):
        image = Image.open("edible_example.jpg")
        st.image(image, caption="ç¤ºä¾‹ï¼šå¯é£Ÿè˜‘è‡", use_container_width=True)
        download_model()
        model, transform, class_names = load_model(MODEL_PATH)
        pred, prob = predict_image(image, model, transform)
        msg = get_interpretation(pred, prob)
        if pred == 1:
            st.markdown(f"<div class='warning-box'>{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰</div>", unsafe_allow_html=True)
        else:
            st.success(f"{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰")

# ä¸Šä¼ å›¾åƒè¯†åˆ«
st.markdown("---")
uploaded_file = st.file_uploader("æˆ–è€…ä¸Šä¼ ä½ è‡ªå·±çš„è˜‘è‡ç…§ç‰‡ï¼š", type=["jpg", "jpeg", "png"])
if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
    download_model()
    model, transform, class_names = load_model(MODEL_PATH)
    pred, prob = predict_image(image, model, transform)
    msg = get_interpretation(pred, prob)
    if pred == 1:
        st.markdown(f"<div class='warning-box'>{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰</div>", unsafe_allow_html=True)
    else:
        st.success(f"{msg}ï¼ˆç½®ä¿¡åº¦ï¼š{prob:.2f}ï¼‰")
